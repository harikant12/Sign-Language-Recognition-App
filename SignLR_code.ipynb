{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16306eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import all required labraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# save and run\n",
    "\n",
    "# now define path to dataset\n",
    "path=\"ImagePro\"\n",
    "files=os.listdir(path)\n",
    "# list of files in path\n",
    "# sort path from A-Y\n",
    "files.sort()\n",
    "\n",
    "# print to see list\n",
    "print(files)\n",
    "\n",
    "\n",
    "# create list of image and label\n",
    "\n",
    "image_array=[]\n",
    "label_array=[]\n",
    "# loop through each file in files\n",
    "\n",
    "for i in tqdm(range(len(files))):\n",
    "\t# list of image in each folder\n",
    "\tsub_file=os.listdir(path+\"/\"+files[i])\n",
    "\t# let's check length of each folder\n",
    "\t#\tprint(len(sub_file))\n",
    "\n",
    "\t# loop through each sub folder\n",
    "\tfor j in range(len(sub_file)):\n",
    "\n",
    "\t\t# path of each image\n",
    "\t\t#Example:imagepro/A/image_name1.jpg\n",
    "\n",
    "\t\tfile_path=path+\"/\"+files[i]+\"/\"+sub_file[j]\n",
    "\t\t# read each image\n",
    "\n",
    "\t\timage=cv2.imread(file_path)\n",
    "\n",
    "\t\t# resize image by 96x96\n",
    "\t\timage=cv2.resize(image,(96,96))\n",
    "\t\t# convert BGR image to RGB image\n",
    "\t\timage=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\t\t# add this image at image_array\n",
    "\t\timage_array.append(image)\n",
    "\n",
    "\t\t# add label to label_array\n",
    "\t\t# i is number from 0 to len(files)-1\n",
    "\t\t# so we can use it as label\n",
    "\t\tlabel_array.append(i)\n",
    "\n",
    "# save and run to see if it is working or not\n",
    "# before that apply tqdm to for loop\n",
    "# it is working with no errors\n",
    "\n",
    "# convert list to array\n",
    "\n",
    "image_array=np.array(image_array)\n",
    "label_array=np.array(label_array,dtype=\"float\")\n",
    "\n",
    "# split the dataset into test and train\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# output\t\t\t\t\t\t\t\t\t   train image   label      spliting size\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(image_array,label_array,test_size=0.15)\n",
    "\n",
    "del image_array,label_array\n",
    "\n",
    "# to free memory \n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# X_train will have 85% of images \n",
    "# X_test will have 15% of images\n",
    "\n",
    "\n",
    "# Create a model\n",
    "from keras import layers,callbacks,utils,applications,optimizers\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "model=Sequential()\n",
    "# add pretrained models to Sequential model\n",
    "# I will use EfficientNetB0 pretrained model. You can try different model.\n",
    "pretrained_model=tf.keras.applications.EfficientNetB0(input_shape=(96,96,3),include_top=False)\n",
    "model.add(pretrained_model)\n",
    "\n",
    "# add Pooling to model\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "# add dropout to model\n",
    "# We add dropout to increase accuracy by reduce overfitting\n",
    "model.add(layers.Dropout(0.3))\n",
    "# finally we will addd dense layer as an output\n",
    "model.add(layers.Dense(1))\n",
    "# For some tensorflow version we required to build model\n",
    "model.build(input_shape=(None,96,96,3))\n",
    "\n",
    "\n",
    "# to see model summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# save and run to see model summary \n",
    "# make sure your pc is connected to internet to download pretrained weight\n",
    "# It will take some time\n",
    "# Everything till now works\n",
    "# I am using GPU to train model so it will take 20-30 min.\n",
    "# If you train model on CPU it will take some time\n",
    "\n",
    "# compile model\n",
    "# you can use different optimizer and loss function to increase accuracy\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss=\"mae\",metrics=[\"mae\"])\n",
    "\n",
    "# create a checkpoint to save best accuracy model\n",
    "ckp_path=\"trained_model/model\"\n",
    "model_checkpoint=tf.keras.callbacks.ModelCheckpoint(\n",
    "filepath=ckp_path,\n",
    "monitor=\"val_mae\",\n",
    "mode=\"auto\",\n",
    "save_best_only=True,\n",
    "save_weights_only=True\n",
    ")\n",
    "# monitor: monitor validation mae loss to save model\n",
    "# mode: Use to save model when val_mae is minimum or maximum\n",
    "# It has 3 option: \"min\",\"max\",\"auto\".\n",
    "# for us you can select either \"min\" or \"auto\"\n",
    "# When val_mae reduce model will be saved\n",
    "# save_best_only: False -> It will save all model\n",
    "# save_weights_only: Save only weight.\n",
    "\n",
    "\n",
    "# create learning rate reducer to reduce lr when accuracy does not improve\n",
    "# Correct \n",
    "reduce_lr=tf.keras.callbacks.ReduceLROnPlateau(\n",
    "factor=0.9,\n",
    "monitor=\"val_mae\",\n",
    "mode=\"auto\",\n",
    "cooldown=0,\n",
    "patience=5,\n",
    "verbose=1,\n",
    "min_lr=1e-6)\n",
    "\n",
    "# factor: when it is reduce next lr will be 0.9 times of current\n",
    "# next lr= 0.9* current lr\n",
    "\n",
    "# patience=X\n",
    "# reduce lr after X epoch when accuracy does not improve\n",
    "# verbose : show it after every epoch\n",
    "\n",
    "# min_lr : minimum learning rate \n",
    "\n",
    "# Start training model\n",
    "\n",
    "Epochs=100\n",
    "Batch_Size=32\n",
    "# Select batch size according to your Graphic card \n",
    "#\n",
    "#X_train,X_test,Y_train,Y_test\n",
    "history=model.fit(\n",
    "X_train,\n",
    "Y_train,\n",
    "validation_data=(X_test,Y_test),\n",
    "batch_size=Batch_Size,\n",
    "epochs=Epochs,\n",
    "callbacks=[model_checkpoint,reduce_lr]\n",
    ")\n",
    "# Before training you can delete image_array and label_array to increase ram memory \n",
    "\n",
    "# Some error correction\n",
    "# This code will be in the description so you can cross check everything\n",
    "# Save and run \n",
    "# Everything is working\n",
    "\n",
    "# after the training is done load best model\n",
    "\n",
    "model.load_weights(ckp_path)\n",
    "\n",
    "# convert model to tensorflow lite model\n",
    "\n",
    "converter=tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model=converter.convert()\n",
    "\n",
    "# save model\n",
    "with open(\"model.tflite\",\"wb\") as f:\n",
    "\tf.write(tflite_model)\n",
    "\n",
    "# if you want to see prediction result on test dataset\n",
    "prediction_val=model.predict(X_test,batch_size=32)\n",
    "\n",
    "# print first 10 values\n",
    "print(prediction_val[:10])\n",
    "# print first 10 values of Y_test\n",
    "print(Y_test[:10])\n",
    "\n",
    "# Save and run this python file\n",
    "# Before that I will show you\n",
    "# loss: 0.4074 - mae: 0.4074 - val_loss: 0.3797 - val_mae: 0.3797\n",
    "# we have mae and val_mae:\n",
    "# mae: Is on X_train\n",
    "# val_mae: X_test\n",
    "# If val_mae is reducing that means your model is improving.\n",
    "\n",
    "# I will show you the result after the training is over\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877091c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "if vc.isOpened(): # try to get the first frame\n",
    "    is_capturing, frame = vc.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)    # makes the blues image look real colored\n",
    "    webcam_preview = plt.imshow(frame)    \n",
    "else:\n",
    "    is_capturing = False\n",
    "\n",
    "while is_capturing:\n",
    "    try:    # Lookout for a keyboardInterrupt to stop the script\n",
    "        is_capturing, frame = vc.read()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)    # makes the blues image look real colored\n",
    "        webcam_preview.set_data(frame)\n",
    "        plt.draw()\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "\n",
    "        plt.pause(0.1)    # the pause time is = 1 / framerate\n",
    "    except KeyboardInterrupt:\n",
    "        vc.release()\n",
    "        \n",
    "\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4e8611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
